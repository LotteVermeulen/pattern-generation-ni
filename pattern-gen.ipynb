{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Generation Notebook\n",
    "Contents:\n",
    "- [Prerequisites](#Prerequisites)\n",
    "- [Pattern Generation](#pattern-generation)\n",
    "    - [Settings](#settings)\n",
    "    - [Static Generation](#static-generation)\n",
    "    - [REED Patterns](#reed-patterns)\n",
    "    - [Dynamic Generation](#dynamic-generation)\n",
    "- [Generators](#generators)\n",
    "    - [Static Generator](#static-generator)\n",
    "    - [Dynamic Generator](#dynamic-generator)\n",
    "- [Simulated Annealing](#simulated-annealing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "To run the scripts in this notebook we require some modules.\n",
    "To install the modules run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU MUST BE RUNNING PYTHON 3.7.X\n",
    "# HIGHER VERSIONS DO. NOT. WORK.\n",
    "from platform import python_version\n",
    "from io import UnsupportedOperation\n",
    "if python_version()[0:3] != '3.7':\n",
    "    raise Exception(\"You must be running Python 3.7.X\")\n",
    "\n",
    "# System libraries\n",
    "# Json may appear to not be used, but it's used for commented-out conversion code.\n",
    "import json, os, sys, string, random, subprocess, time, shutil, datetime\n",
    "from collections.abc import Callable, Mapping\n",
    "from typing import Tuple\n",
    "print(\"System libraries imported.\")\n",
    "\n",
    "# Import external modules\n",
    "try:\n",
    "    import gifutils # This is a local library with dependencies, so it is in this list too.\n",
    "    # If you run into an issue with it, please make sure the dependencies are in requirements.txt, or resolve it manually.\n",
    "    import numpy as np\n",
    "    import scipy.signal\n",
    "    import wget\n",
    "    import psutil\n",
    "except ImportError:\n",
    "    print(\"Required libraries missing, installing them...\")\n",
    "    subprocess.call(['pip3', 'install', '-r', 'requirements.txt', '--no-warn-script-location'])\n",
    "    import gifutils\n",
    "    import numpy as np\n",
    "    import scipy.signal\n",
    "    import wget\n",
    "    import psutil\n",
    "print(\"All libraries imported.\")\n",
    "\n",
    "# Import visil package\n",
    "try:\n",
    "    from visil.model.visil import ViSiL\n",
    "    from visil.datasets import load_video\n",
    "except ImportError:\n",
    "    print(\"Missing visil package...\")\n",
    "\n",
    "    import tensorflow as tf\n",
    "    if tf.__version__ != '1.15.1':\n",
    "        print(\"Cloning original (non-compat) package...\")\n",
    "        subprocess.call(['git', 'clone', 'https://github.com/MKLab-ITI/visil'])\n",
    "    else:\n",
    "        print(\"Cloning compat package...\")\n",
    "        subprocess.call(['git', 'clone', 'https://github.com/teamhart-nl/visil'])\n",
    "    print(\"Installing dependencies...\")\n",
    "    subprocess.call(['pip3', 'install', '-r', 'visil/requirements.txt', '--no-warn-script-location'])\n",
    "    from visil.model.visil import ViSiL\n",
    "    from visil.datasets import load_video\n",
    "print(\"Visil package loaded.\")\n",
    "\n",
    "# Load model\n",
    "try:\n",
    "    if not os.path.exists('ckpt/resnet'):\n",
    "        raise Exception(\"L\")\n",
    "    print(\"Loading model. Tensorflow deprecation warnings are expected but safe to ignore.\")\n",
    "    model = ViSiL('ckpt/resnet/')\n",
    "except Exception:\n",
    "    print(\"Required model missing, installing it...\")\n",
    "    from zipfile import ZipFile\n",
    "    if not os.path.exists('ckpt.zip'):\n",
    "        print(\"Downloading model from http://ndd.iti.gr/visil/ckpt.zip, this may take a while...\")\n",
    "        wget.download('http://ndd.iti.gr/visil/ckpt.zip')\n",
    "    print(\"Unzipping model...\")\n",
    "    ZipFile('ckpt.zip', 'r').extractall()\n",
    "    print(\"Loading model...\")\n",
    "    model = ViSiL('ckpt/resnet/')\n",
    "print(\"Model loaded.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Verification\n",
    "# Let's try loading the 2 example videos and calculating the score\n",
    "# This is optional, but it's a good way to check if the model is working\n",
    "v1 = load_video('visil/examples/video1.gif')\n",
    "v2 = load_video('visil/examples/video2.gif')\n",
    "v1features = model.extract_features(v1, batch_sz=32)\n",
    "v2features = model.extract_features(v2, batch_sz=32)\n",
    "similarity = model.calculate_video_similarity(v1features, v2features)\n",
    "similarity = round(similarity, 2)\n",
    "\"Successfully setup model!\" if similarity > 0.3 and similarity < 0.8 else \"Model setup failed!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Generation\n",
    "We generate patterns using one of two methods:\n",
    "- [Static Generation](#static-generation)\n",
    "- [Dynamic Generation](#dynamic-generation)\n",
    "\n",
    "Static generation generates a sequence of frames where the same actuators are used in all frames.\n",
    "Dynamic generation, on the other hand, generates a sequence of frames with different actuators, that give a shape or motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "FPS = 10\n",
    "GRID_WIDTH = 4\n",
    "GRID_HEIGHT = 6\n",
    "MIN_ACTUATORS = 1\n",
    "MAX_ACTUATORS = 8\n",
    "AMPLITUDES = [100, 255]\n",
    "FREQUENCIES = [69]\n",
    "MODULATIONS = [8]\n",
    "WAVEFORMS = [\"sin\", \"sawtooth\", \"block\", \"hanning\", \"constant\"]\n",
    "CHANNELS = {\n",
    "    \"red\": \"amplitude\",\n",
    "    \"green\": \"amplitude\",\n",
    "    \"blue\": \"amplitude\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Generation\n",
    "Generates a sequence of frames where the same actuators are used in all frames.\n",
    "\n",
    "*Description goes here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type of E: 'set' which is a subset of (4,6), e in E, e[0] is '4', e[1] is '6'\n",
    "# type of D: duration in of the pattern (integer in ms)\n",
    "# type of G_f: frequency of wave type (integer)\n",
    "# type of W: string, denoting the wave type\n",
    "\n",
    "POSSIBLE_WAVEFORMS = ['sin', 'sawtooth', 'block', 'hanning', 'constant']\n",
    "\n",
    "\n",
    "def staticPattern(E, a, f, d, g_f, w) -> list:\n",
    "    \"\"\"\n",
    "    #TODO: add drawing somewhere\n",
    "\n",
    "    We say 'extra' is a parameter either a or f.\n",
    "    We say 'x' is from top view of the grid the x-coordinate\n",
    "    We say 'y' is from top view of the grid the y-coordinate\n",
    "\n",
    "    :param E: (array) subset of whole grid. E = E[e_1,e_2,...]. For each e in E: x=e[0], y=e[1]\n",
    "    :param a: (int: mm) one of all amplitudes. a = a in A\n",
    "    :param f: (int: Hz) one of all frequencies. f = f in F\n",
    "    :param d: (int: ms) one of all durations. d = d in D ()\n",
    "    :param g_f: (int) one of all group frequencies. g_f = g_f in G_f. Also known as 'modulation'\n",
    "    :param w: (str) one of all wave types. w = w in W\n",
    "    :return: array: (array) an array representing the pattern in video form. array = array[time][x][y][extra].\n",
    "             note that array[][][][0] gives the frequency, and array[][][][1] gives the amplitude.\n",
    "             \"\"\"\n",
    "\n",
    "    # initial values\n",
    "    max_amp = 250\n",
    "    delta_t = 10\n",
    "    discretization = d // delta_t\n",
    "    array = np.zeros(shape=(discretization,4,6,2)) #maybe useful to make this a custom class\n",
    "\n",
    "    if w == 'constant':\n",
    "        for timestep in range(discretization):\n",
    "            for e in E:\n",
    "                array[timestep][e[0]-1][e[1]-1][0] = f\n",
    "                array[timestep][e[0]-1][e[1]-1][1] = a\n",
    "\n",
    "    elif w == 'sin':\n",
    "        # Note that we assume a sine wave y = A sin(B(x-phi))+D\n",
    "\n",
    "        # Computed from input\n",
    "        B = 2*np.pi*g_f\n",
    "        A = (max_amp - 0.5*max_amp)/2   # assuming a sin wave with 0.5*max_amp amplitude\n",
    "        D = max_amp - A                 # wave between max_amp and max_amp/2\n",
    "\n",
    "        # For creating wave\n",
    "        start = 0\n",
    "        stop = d\n",
    "        x = np.linspace(start, stop, discretization)\n",
    "\n",
    "        #create amplitude list\n",
    "        phi = 0\n",
    "        amplitude_list = []\n",
    "        for i in range(len(x)):\n",
    "            amplitude_list.append((int) (A*np.sin(B*(x[i] - phi)) + D))\n",
    "\n",
    "        for timestep in range(discretization):\n",
    "            for e in E:\n",
    "                array[timestep][e[0]-1][e[1]-1][0] = f\n",
    "                array[timestep][e[0]-1][e[1]-1][1] = amplitude_list[timestep]\n",
    "\n",
    "    elif w == 'sawtooth':\n",
    "        # TODO: add explanation of theoretic function from signal.sawtooth\n",
    "\n",
    "        # Computed from input\n",
    "        B = 2*np.pi*g_f\n",
    "\n",
    "        # for creating a wave\n",
    "        start = 0\n",
    "        stop = d\n",
    "        x = np.linspace(start, stop, discretization)\n",
    "\n",
    "        # Create amplitude list\n",
    "        phi = 0\n",
    "        amplitude_list = []\n",
    "        for i in range(len(x)):\n",
    "            amplitude_list.append((int) ((max_amp*scipy.signal.sawtooth(B * (x[i] - phi)) + max_amp)/2))\n",
    "\n",
    "        for timestep in range(discretization):\n",
    "            for e in E:\n",
    "                array[timestep][e[0]-1][e[1]-1][0] = f\n",
    "                array[timestep][e[0]-1][e[1]-1][1] = amplitude_list[timestep]\n",
    "\n",
    "    elif w == 'hanning':\n",
    "        # Note that we assume a hanning window y = 0.5(1 - cos(2pin/N)), 0 <= n <= N  # noqa: E501\n",
    "        # This function is built into numpy as hanning(discretization_rate).\n",
    "\n",
    "        #create amplitude list\n",
    "        amplitude_list = max_amp * np.hanning(discretization) #hanning window\n",
    "\n",
    "        for timestep in range(discretization):\n",
    "            for e in E:\n",
    "                array[timestep][e[0]-1][e[1]-1][0] = f\n",
    "                array[timestep][e[0]-1][e[1]-1][1] = amplitude_list[timestep]\n",
    "\n",
    "    elif w == 'block':\n",
    "        # Note that we assume a block function y = 1 if 0 <= x < period, -1 if period < x < 2*period\n",
    "\n",
    "        # can be calculated from input\n",
    "        period = 1 / g_f\n",
    "\n",
    "        # for creating wave\n",
    "        start = 0\n",
    "        stop = d\n",
    "        x = np.linspace(start, stop, discretization)\n",
    "\n",
    "        #create amplitude list\n",
    "        phi = 0\n",
    "        amplitude_list = []\n",
    "        for i in range(len(x)):\n",
    "            if x[i] % 2*period < period: # if 0 <= x < period\n",
    "                sign = 1\n",
    "            else: # period <= x < 2*period\n",
    "                sign = -1\n",
    "            amplitude_list.append((int) (a * sign))\n",
    "        for timestep in range(discretization):\n",
    "            for e in E:\n",
    "                array[timestep][e[0]-1][e[1]-1][0] = f\n",
    "                array[timestep][e[0]-1][e[1]-1][1] = amplitude_list[timestep]\n",
    "    else:\n",
    "        print(\"error: wave type unknown\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    return array\n",
    "\n",
    "\"\"\"\n",
    ":param name: (str) name of the pattern\n",
    ":param grid_width: (int) width of the grid\n",
    ":param grid_height: (int) height of the grid\n",
    ":param actuators_no: (tuple) -> (lower, upper) bound on amounts of actuators enabled. \n",
    ":param amplitudes: (list) list of amplitudes\n",
    ":param frequencies: (list) list of frequencies\n",
    ":param modulations: (list) list of modulation frequencies\n",
    ":param durations: (list) list of durations\n",
    ":param waveforms: (list) waveform options, pick one or more from from ['sin', 'sawtooth', 'block', 'hanning', 'constant']\n",
    ":return: tuple of (name: str, pattern: list). Pattern representing the pattern in video form. pattern = pattern[time][x][y][extra].\n",
    "         note that pattern[][][][0] gives the frequency, and pattern[][][][1] gives the amplitude.\n",
    "\"\"\"\n",
    "def generateRandomPattern(\n",
    "    name: str,\n",
    "    grid_width: int = 4,\n",
    "    grid_height: int = 6,\n",
    "    actuators_no: tuple = (1, 8),\n",
    "    amplitudes: list = [100, 255],\n",
    "    frequencies: list = [69],\n",
    "    modulations: list = [8],\n",
    "    durations: list = [92, 392],\n",
    "    waveforms: list = POSSIBLE_WAVEFORMS) -> tuple:\n",
    "\n",
    "    actuators = random.randint(actuators_no[0], actuators_no[1])\n",
    "    amplitude = random.choice(amplitudes)\n",
    "    frequency = random.choice(frequencies)\n",
    "    modulation = random.choice(modulations)\n",
    "    duration = random.choice(durations)\n",
    "    waveform = random.choice(waveforms)\n",
    "    waveform = random.choice(POSSIBLE_WAVEFORMS) if not waveform in POSSIBLE_WAVEFORMS else waveform\n",
    "\n",
    "    enabled_actuators = [(random.randint(1,grid_width), random.randint(1,grid_height)) for _ in range (actuators)]\n",
    "\n",
    "    return (name, staticPattern(enabled_actuators, amplitude, frequency, duration, modulation, waveform))\n",
    "\n",
    "\"\"\"\n",
    ":param name: (str) name of the pattern\n",
    ":param grid: np.ndarray representing the pattern in video form. gird = grid[time][x][y][extra].\n",
    "         note that grid[][][][0] gives the frequency, and grid[][][][1] gives the amplitude.\n",
    ":param out_directory: (str) directory to save the patterns to\n",
    ":param grid_width: (int) width of the grid\n",
    ":param grid_height: (int) height of the grid\n",
    ":param channel_red: (str) amplitude or frequency\n",
    ":param channel_green: (str) amplitude or frequency\n",
    ":param channel_blue: (str) amplitude or frequency\n",
    "\"\"\"\n",
    "def generateGIF(\n",
    "    name: string,\n",
    "    grid: np.ndarray,\n",
    "    out_directory: str = 'gifs',\n",
    "    grid_width: int = 4,\n",
    "    grid_height: int = 6,\n",
    "    channel_red: str = \"amplitude\",\n",
    "    channel_green: str = \"amplitude\",\n",
    "    channel_blue: str = \"amplitude\") -> None:\n",
    "\n",
    "    grids = [[[[255, 255, 255] for _ in range(grid_width)] for _ in range(grid_height)] for _ in range(len(grid))]\n",
    "\n",
    "    for index, _ in np.ndenumerate(grid):\n",
    "        # index:\n",
    "        # (i, j, k, l) where:\n",
    "        frame = grid[index[0]]\n",
    "\n",
    "        for column_id, column in enumerate(frame):\n",
    "            for row_id, row in enumerate(column):\n",
    "                if channel_red == \"frequency\" or channel_green == \"frequency\" or channel_blue == \"frequency\":\n",
    "                    raise UnsupportedOperation(\"frequency channel not supported yet\")\n",
    "                amp = frame[column_id][row_id][1]\n",
    "                red = 255 - amp\n",
    "                green = 255 - amp\n",
    "                blue = 255 - amp\n",
    "                grids[index[0]][row_id][column_id] = [red, green, blue]\n",
    "\n",
    "    gifutils.save_frames_as_gif(gifutils.frames_from_lists(grids), out_directory, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REED patterns\n",
    "The set of patterns from the REED paper. These use the static method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "sp = namedtuple('static_pattern', 'phoneme total_time modulation fraction phi dis coord_list pho_freq')\n",
    "\n",
    "reed_data = [\n",
    "    sp('B',  92, 30, 0.5, 0, 6, [[1,5],[1,6],[2,5],[2,6]], 300),\n",
    "    sp('M', 392, 8, 0.5, 0, 12,  [[1,5],[1,6],[2,5],[2,6]], 60),\n",
    "    sp('J', 392, 8, 0.5, 0, 12, [[1,1],[1,6],[2,1],[2,6]], 300),\n",
    "    sp('D',  92, 30, 0.5, 0, 6, [[3,3],[3,4],[4,3],[4,4]], 300),\n",
    "    sp('G',  92, 30, 0.5, 0, 6, [[1,1],[1,2],[2,1],[2,2]], 300),\n",
    "    sp('V', 392, 8, 0.5, 0, 12, [[1,6],[2,6],[3,6],[4,6]], 300),\n",
    "    sp('DH',392, 8, 0.5, 0, 12,[[1,3],[1,4],[2,3],[2,4]], 300),\n",
    "    sp('Z', 392, 8, 0.5, 0, 12, [[1,1],[2,1],[3,1],[4,1]], 300),\n",
    "    sp('ZH',392, 8, 0.5, 0, 12,[[3,1],[3,2],[4,1],[4,2]], 60),\n",
    "    sp('N', 392, 8, 0.5, 0, 12, [[3,3],[3,4],[4,3],[4,4]], 60),\n",
    "    sp('NG',392, 8, 0.5, 0, 12,[[1,1],[1,2],[2,1],[2,2]], 60),\n",
    "    sp('W', 392, 8, 0.5, 0, 12, [[1,3],[1,4],[1,5],[1,6],[3,3],[3,4],[3,5],[3,6]], 60),\n",
    "    sp('L', 392, 30, 0.5, 0, 12,[[3,5],[3,6],[4,5],[4,6]], 300),\n",
    "    sp('R', 392, 30, 0.5, 0, 12,[[3,1],[3,2],[4,1],[4,2]], 300),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deprecated Type definitions\n",
    "E = []\n",
    "a = -1\n",
    "d = -1\n",
    "f = -1\n",
    "g_f = -1\n",
    "w = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # type of E_j: 'set' which is a subset of (4,6), e in E, e[0] is '4', e[1] is '6'\n",
    "# P_j is for j=3: [P_1, P_2, P_3]\n",
    "# P_j is a list of 2 rows, where\n",
    "# \tP_j[0] contains number dt\n",
    "# \tP_j[1] consists of a list of [E_0, E_1, ..., E_k] such that\n",
    "# \teach exciter e in E_i starts at time i * dt\n",
    "\n",
    "# D_j is a list of durations, where D_j[i] is the amount of\n",
    "# \ttime the exciters in P_j[1][i] is active\n",
    "# A_j is a list of amplitudes where A_j[i] is the amplitude\n",
    "# \tof the group wave for the exciters in P_j[1][i]\n",
    "# F_j\n",
    "# G_F_j\n",
    "# W_j\n",
    "\n",
    "# P[j][E[j]][0] is a set of e's, a subset of (4,6), with dT on last index\n",
    "\n",
    "def dynamicPattern(P, D, A, F, G_F, W):\n",
    "\t\"\"\"\n",
    "\t#TODO: add drawing somewhere\n",
    "\n",
    "\tWe say 'extra' is a parameter either a or f.\n",
    "\tWe say 'x' is from top view of the grid the x-coordinate\n",
    "\tWe say 'y' is from top view of the grid the y-coordinate\n",
    "\n",
    "\tWe say 'dt[i]' is t_start[i] - t_start[i-1] (see drawing)\n",
    "\n",
    "\t:param P: (array) P = P[P_1,P_2,...]. P_j=[P_j[0],P_j[1]], where P_j[0] = dt,\n",
    "\t\t      P_j[1] = [E_0,E_1,...], where e in E_i starts at time i*dt.\n",
    "\t:param D: (array) list of durations. D_j = [D_j[0],D_j[1],...],\n",
    "\t\t\t  where D_j[i] is the amount of time the exciters in P_j[1][i] is active.\n",
    "\t:param A: (array) list of amplitudes. A_j = [A_j[0],A_j[1],...],\n",
    "\t\t\t  where A_j[i] is the amplitude of the exciters in P_j[1][i].\n",
    "\t:param F: (array) list of frequencies. F_j = [F_j[0],F_j[1],...],\n",
    "\t\t\t  where F_j[i] is the frequency of the exciters in P_j[1][i].\n",
    "\t:param G_F: (array) list of group frequencies. G_F_j = [G_F_j[0],G_F_j[1],...],\n",
    "\t\t\t  where G_F_j[i] is the group frequency of the exciters in P_j[1][i].\n",
    "\t:param W: (array) list of wave types. W_j = [W_j[0],W_j[1],...],\n",
    "\t\t\t  where W_j[i] is the wave type of the exciters in P_j[1][i].\n",
    "\t:return: array: (array) an array representing the pattern in video form. array = array[time][x][y][extra].\n",
    "\t\t\t note that array[][][][0] gives the frequency, and array[][][][1] gives the amplitude.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdiscretization = sum([sum(D[i]) for i in range(len(D))]) // 10\n",
    "\tarray = np.zeros(size=(discretization,4,6,2)) #maybe useful to make this a custom class\n",
    "\n",
    "\n",
    "\t# for j in range(len(P)):\n",
    "\t# \tfor i in range(len(P)):\n",
    "\t# \t\tif W[j][i] == 'constant':\n",
    "\t# \t\t\tfor timestep in range(D[][]):\n",
    "\t# \t\t\t\tfor e in [P[j][1][i]]:\n",
    "\t# \t\t\t\t\tarray[timestep][P[j][1][i]][0] =\n",
    "\t# \t\t\t\t\tarray[timestep][P[j][1][i]][0] =\n",
    "\n",
    "# Example input, |j|=2\n",
    "dt_example = [0 for _ in range(2)]\n",
    "\n",
    "e_111 = [2, 4]\n",
    "e_112 = [2, 3]\n",
    "E_11 = [e_111, e_112]\n",
    "\n",
    "e_121 = [1, 2]\n",
    "e_122 = [2, 2]\n",
    "E_12 = [e_121, e_122]\n",
    "\n",
    "E_example = [E_11, E_12]\n",
    "P_1 = [dt_example, E_example] #E['dt',[E_11,E_12]]\n",
    "P_2 = P_1\n",
    "P = [P_1,P_2]  # [[[dt_example],[[E_11],[E_12]]], [[dt_example],[[E_21],[E_22]]]]\n",
    "print(P)\n",
    "\n",
    "D_1 = [400, 400]\n",
    "D_2 = [200, 200]\n",
    "D = [D_1, D_2]\n",
    "# print(sum([sum(D[i]) for i in range(len(D))]))\n",
    "\n",
    "A_1 = [250, 250]\n",
    "A_2 = [250, 250]\n",
    "A = [A_1, A_2]\n",
    "\n",
    "F_1 = [300, 300]\n",
    "F_2 = [60, 60]\n",
    "F = [F_1, F_2]\n",
    "\n",
    "G_F_1 = [30, 30]\n",
    "G_F_2 = [30, 30]\n",
    "G_F = [G_F_1, G_F_2]\n",
    "\n",
    "W_1 = ['constant', 'constant']\n",
    "W_2 = ['sawtooth', 'sawtooth']\n",
    "W = [W_1, W_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generators\n",
    "### Static Generator\n",
    "Generate static patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTUATORS_MIN = 4\n",
    "ACTUATORS_MAX = 8\n",
    "N_PATTERNS = 3000 # 1000 take about 1 minute to generate\n",
    "GIF_DIRECTORY = 'gifs/'\n",
    "for i in range(N_PATTERNS):\n",
    "    p_name = 'p_' + str(i)\n",
    "    if os.path.exists(GIF_DIRECTORY + p_name + \".gif\"):\n",
    "        continue\n",
    "    generateGIF(p_name, generateRandomPattern(p_name, actuators_no=(ACTUATORS_MIN, ACTUATORS_MAX))[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Annealing\n",
    "We have 44 phonemes that require a pattern. These patterns need to be distinguishable from eachother, to the highest degree possible.  \n",
    "Below is a model which can compare two patterns, pairwise only. At the bottom an overview of the methods of pattern collection is given.\n",
    "\n",
    "#### Pairwise Model\n",
    "https://github.com/MKLab-ITI/visil provides a pretrained model for video distinguishability (referred to as ViSiL).\n",
    "We shall use this model as a baseline for pairwise pattern distinguishability.\n",
    "\n",
    "#### Complete Patterns Model\n",
    "The above model gives us the possibility to calculate the total score of a pair, but does not provide a method for quickly calculating the score of a collection of patterns.\n",
    "There is of course the brute force method, generating a new set of patterns and getting the score for them, improving over time, but this is not practical due to runtime.\n",
    "So we will be using Simulated Annealing (SA) to find the best set of patterns.\n",
    "\n",
    "#### Simulated Annealing (SA)\n",
    "Simulated Annealing is a method where the score of a collection of patterns is improved by starting with a random collection of patterns, and then iteratively changing the collection of patterns by (sub)randomly changing one of the patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__PATTERN_CACHE__ = {}\n",
    "def make_or_get_cached_pattern(file: str):\n",
    "    filehash = hash(file)\n",
    "    if filehash not in __PATTERN_CACHE__:\n",
    "        __PATTERN_CACHE__[filehash] = Pattern(file)\n",
    "    return __PATTERN_CACHE__[filehash]\n",
    "\n",
    "class Pattern:\n",
    "\n",
    "    def __init__(self, file: str):\n",
    "        self.file = file\n",
    "        self.features = model.extract_features(load_video(GIF_DIRECTORY + \"/\" + file), batch_sz=32)\n",
    "\n",
    "    def get_features(self):\n",
    "        return self.features\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.file.replace(\".gif\", \"\").replace(\"p_\", \"\")\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.file == other.file\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair_score_function(x: Pattern, y: Pattern):\n",
    "    if x == y:\n",
    "        return 1\n",
    "    return model.calculate_video_similarity(x.get_features(), y.get_features())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIF_FILES = [f for f in os.listdir(GIF_DIRECTORY) if f.endswith('.gif')] # Note: any newly generated patterns are not in this list\n",
    "if len(GIF_FILES) == 0:\n",
    "    print('No GIFs found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a pattern that is not in existing_set\n",
    "def get_new_pattern(existing_set: list = []) -> Pattern:\n",
    "    tries = 0\n",
    "    pattern: Pattern = None\n",
    "    while tries < 1000:\n",
    "        pattern = make_or_get_cached_pattern(random.choice(GIF_FILES))\n",
    "        if pattern in existing_set:\n",
    "            tries += 1\n",
    "            continue\n",
    "        return pattern\n",
    "\n",
    "\"estimated \" + str(sys.getsizeof(get_new_pattern())) + \" bytes per pattern\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SET_SIZE = 44 # Amount of patterns in the set\n",
    "COOLING_RATE = 0.99995 # Factor per iteration\n",
    "INITIAL_TEMP = 0.005 # Initial temperature. Temp is chance to accept worse solution.\n",
    "MIN_TEMP = 0.0000005 # Minimum temperature.\n",
    "SCORE_PICKING = np.median # Algorithm to pick set score. Should take a list of float (float32) and return a float (float32).\n",
    "UPDATE_TIME_MS = 10_000 # Miliseconds for the next update\n",
    "BEST_SET = None # Best set found so far, used below \\/\n",
    "INITIAL_SET: list = None if BEST_SET == None else [make_or_get_cached_pattern(\"p_\" + str(x) + \".gif\") for x in BEST_SET] # Initial set of patterns. If None, will be generated randomly.\n",
    "ITERATIONS = round(np.log(MIN_TEMP / INITIAL_TEMP) / np.log(COOLING_RATE)) # Number of iterations until lower bound is reached.\n",
    "str(ITERATIONS) + \" iterations!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some debug util methods\n",
    "def round_to_sign_digits(x: float, digits: int = 2) -> str:\n",
    "    return '{:g}'.format(float('{:.{p}g}'.format(x, p=digits)))\n",
    "\n",
    "__SCORE_CACHE__: Mapping = {} # Do not modify this variable elsewhere!\n",
    "def get_pattern_pair_score(x: Pattern, y: Pattern) -> np.float32:\n",
    "    if (x.file, y.file) in __SCORE_CACHE__:\n",
    "        return __SCORE_CACHE__[(x.file, y.file)]\n",
    "    else:\n",
    "        score = 1 - abs(get_pair_score_function(x, y))\n",
    "        __SCORE_CACHE__[(x.file, y.file)] = score\n",
    "        __SCORE_CACHE__[(y.file, x.file)] = score\n",
    "        return score\n",
    "\n",
    "# Debug the simulated annealing algorithm in a one-liner\n",
    "__DEBUGCACHE__ = {'time': time.time(), 'iterations': -1}\n",
    "def debug_sa(iteration: int, total_iterations: int, temperature: float, min_temp: float, current_score: float, current_set: list, additional_info: str = \"\"):\n",
    "    if time.time() - __DEBUGCACHE__['time'] < UPDATE_TIME_MS / 1000 and iteration != 0:\n",
    "        return\n",
    "\n",
    "    time_since_update = (time.time() - __DEBUGCACHE__['time']) * 1000\n",
    "    time_per_iteration = time_since_update / (iteration - __DEBUGCACHE__['iterations']) if iteration - __DEBUGCACHE__['iterations'] > 0 else 0\n",
    "    time_ETA = (total_iterations - iteration) * time_per_iteration / 1000\n",
    "    pattern_cache_filled = len(__PATTERN_CACHE__) / len(GIF_FILES) * 100\n",
    "    score_cache_filled = len(__SCORE_CACHE__) / (len(GIF_FILES) ** 2) * 50\n",
    "\n",
    "    message = '{}I {}/{} ({}%)\\t{}ms/I, ETA {}s\\tT={}% > {}%\\tPC={}% / SC={}%\\tS={}'.format(\n",
    "        additional_info + \" | \" if additional_info != \"\" else \"\",\n",
    "        iteration,\n",
    "        total_iterations,\n",
    "        round_to_sign_digits(iteration / total_iterations * 100, 3),\n",
    "        round_to_sign_digits(time_per_iteration),\n",
    "        round_to_sign_digits(time_ETA),\n",
    "        round_to_sign_digits(temperature * 100),\n",
    "        round_to_sign_digits(min_temp * 100),\n",
    "        round_to_sign_digits(pattern_cache_filled, 4),\n",
    "        round_to_sign_digits(score_cache_filled, 4),\n",
    "        round_to_sign_digits(current_score, 4)\n",
    "    )\n",
    "    print(message)\n",
    "    # write to gen.log\n",
    "    with open('gen.log', 'a') as f:\n",
    "        f.write(message + \"\\tC=\" + str(current_set) + '\\n')\n",
    "\n",
    "    __DEBUGCACHE__['time'] = time.time()\n",
    "    __DEBUGCACHE__['iterations'] = iteration\n",
    "\n",
    "debug_sa(0, 1, 0, 0, False, [])\n",
    "\n",
    "def get_set_score(element_list: list, score_picking: Callable) -> np.float32:\n",
    "    scores = []\n",
    "    for i, x in enumerate(element_list):\n",
    "        for j, y in enumerate(element_list):\n",
    "            if i == j:\n",
    "                continue\n",
    "            scores.append(get_pattern_pair_score(x, y))\n",
    "            \n",
    "    return score_picking(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SA(element_set: list, score_picking: Callable = SCORE_PICKING, update_time: int = UPDATE_TIME_MS, temperature: float = INITIAL_TEMP,\n",
    "       cooling_rate: float = COOLING_RATE, iterations: int = ITERATIONS, temp_lower_bound: float = MIN_TEMP) -> Tuple[Pattern, np.float32]:\n",
    "    \n",
    "    # Print SA details\n",
    "    print(\"Starting {} iterations of Simulated Annealing on set of size {}, initial temp {}, temp lower bound {}, and a cooling rate of {}.\\nUpdates every {} seconds, after an iteration finishes.\"\n",
    "         .format(iterations, len(element_set), temperature, temp_lower_bound, cooling_rate, round_to_sign_digits(update_time / 1000, 3)))\n",
    "    \n",
    "    # Get the current score of the set\n",
    "    print(\"Generating initial score. This may take a while...\")\n",
    "    current_score = get_set_score(element_set, score_picking)\n",
    "\n",
    "    # 0th debug\n",
    "    debug_sa(0, iterations, temperature, temp_lower_bound, current_score, element_set, \"Initial\")\n",
    "\n",
    "    # Run through iterations\n",
    "    for i in range(1, iterations + 1):\n",
    "\n",
    "        # Create a copy of the set\n",
    "        new_element_set = element_set.copy()\n",
    "\n",
    "        # Replace a pattern in the set with a new one\n",
    "        new_element_set[random.randint(0, len(new_element_set) - 1)] = get_new_pattern(new_element_set)\n",
    "        \n",
    "        # Get the score of the new set\n",
    "        new_score = get_set_score(new_element_set, score_picking)\n",
    "\n",
    "        # If the new score is better, keep the new set\n",
    "        if new_score > current_score:\n",
    "            element_set = new_element_set\n",
    "            current_score = new_score\n",
    "\n",
    "        # Else accept the new set with a probability\n",
    "        else:\n",
    "            if np.random.random() < np.exp((new_score - current_score) / temperature):\n",
    "                element_set = new_element_set\n",
    "                current_score = new_score\n",
    "\n",
    "        # Cool the temperature\n",
    "        temperature *= cooling_rate\n",
    "        \n",
    "        # Stop if the temperature is lower than the lower bound\n",
    "        if temperature <= temp_lower_bound:\n",
    "            debug_sa(i, iterations, temperature, temp_lower_bound, current_score, element_set, \"Temperature lower bound reached\")\n",
    "            break\n",
    "\n",
    "        # Print\n",
    "        debug_sa(i, iterations, temperature, temp_lower_bound, current_score, element_set)\n",
    "    \n",
    "    # Print summary\n",
    "    debug_sa(i, iterations, temperature, temp_lower_bound, current_score, element_set, \"Final\")\n",
    "    \n",
    "            \n",
    "    # Return the new pattern set and its score\n",
    "    return element_set, current_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pattern Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRECACHE_PATTERNS = True # It takes about 600MB of ram per 1000 patterns. It takes about 2 minutes per 1000 patterns to precache.\n",
    "if PRECACHE_PATTERNS:\n",
    "    start_ = time.time()\n",
    "    start = time.time()\n",
    "    memory = psutil.Process(os.getpid()).memory_info().rss / (1024 ** 2) # memory in MB\n",
    "    for i, f in enumerate(GIF_FILES):\n",
    "        if i % 100 == 0:\n",
    "            print(\"Cached {}/{} patterns (took {}s, ETA {}s)\".format(i, len(GIF_FILES), round_to_sign_digits(time.time() - start, 4), round_to_sign_digits((time.time() - start) / 100 * (len(GIF_FILES) - i), 4)))\n",
    "            start = time.time()\n",
    "        make_or_get_cached_pattern(f)\n",
    "    print(\"Cached {} patterns in {}s, using approximately {}MB of memory\".format(len(GIF_FILES), round_to_sign_digits(time.time() - start_, 4), round_to_sign_digits(psutil.Process(os.getpid()).memory_info().rss / (1024 ** 2) - memory, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code example\n",
    "Below an example of how to generate patterns using SA. Uses many of the constants above. Also copies the best patterns to a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patternset = INITIAL_SET\n",
    "if patternset is None:\n",
    "    patternset = []\n",
    "if not len(patternset) == SET_SIZE:\n",
    "    print(\"Generating initial patterns...\")\n",
    "    while len(patternset) < SET_SIZE:\n",
    "        patternset.append(get_new_pattern(patternset))\n",
    "    while len(patternset) > SET_SIZE:\n",
    "        print(\"Removing pattern due to oversizing...\")\n",
    "        patternset.pop()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Running Simulated Annealing...\")\n",
    "patternset, score = SA(patternset)\n",
    "\n",
    "print(\"Ran for {}s. Best retrieved set score is {}, with set: {}.\".format(round_to_sign_digits(time.time() - start), round_to_sign_digits(score, 5), patternset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"BEST\"):\n",
    "    os.mkdir(\"BEST\")\n",
    "\n",
    "for i in patternset:\n",
    "    # Gif file name\n",
    "    gif_file_name = \"p_\" + str(i) + \".gif\"\n",
    "\n",
    "    # Copy the gif file to a directory called \"BEST\" and subdirectory with today's date\n",
    "    # Add the number to the end of the subdirectory name if it already exists.\n",
    "    additional_number = 0\n",
    "    datename = datetime.datetime.today().strftime(\"%Y-%m-%d\")\n",
    "    while os.path.isdir(os.path.join(\"BEST\", datename)):\n",
    "        additional_number += 1\n",
    "        datename = datetime.datetime.today().strftime(\"%Y-%m-%d\") + \"_\" + str(additional_number)\n",
    "\n",
    "    os.mkdir(os.path.join(\"BEST\", datename))\n",
    "    shutil.copy(os.path.join(GIF_DIRECTORY, gif_file_name), os.path.join(\"BEST\", datename, gif_file_name))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85eb52f9e23e796824ac0c541858b8dee2833b318fabf0be87784445f41a811a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
